{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053649fd",
   "metadata": {},
   "source": [
    "# Large Model 을 accelerate를 이용해서 loading하는 예시. \n",
    "\n",
    "offloading by cpu, disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0696e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/huggingface-cache\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "print(os.environ['TRANSFORMERS_CACHE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "269d55e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/huggingface-cache/models--facebook--opt-2.7b/snapshots/397f71a473a150c00f0fe3fc4a2f78ff3ccaf82d/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "checkpoint = 'facebook/opt-2.7b'\n",
    "weights_path = hf_hub_download(checkpoint, 'pytorch_model.bin', cache_dir=os.environ['TRANSFORMERS_CACHE'])\n",
    "print(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73855555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 2560, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 2560)\n",
       "      (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from accelerate import init_empty_weights, dispatch_model, infer_auto_device_map, load_checkpoint_and_dispatch, load_checkpoint_in_model, dispatch_model\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "with init_empty_weights():\n",
    "    model = AutoModelForCausalLM.from_config(config)\n",
    "model.tie_weights()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd50bc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'decoder.embed_tokens': 0, 'decoder.embed_positions': 0, 'decoder.final_layer_norm': 0, 'decoder.layers.0': 0, 'decoder.layers.1': 0, 'decoder.layers.2': 0, 'decoder.layers.3': 0, 'decoder.layers.4': 0, 'decoder.layers.5': 0, 'decoder.layers.6': 0, 'decoder.layers.7': 0, 'decoder.layers.8': 0, 'decoder.layers.9': 0, 'decoder.layers.10': 0, 'decoder.layers.11': 0, 'decoder.layers.12': 0, 'decoder.layers.13': 0, 'decoder.layers.14': 'disk', 'decoder.layers.15': 'disk', 'decoder.layers.16': 'disk', 'decoder.layers.17': 'disk', 'decoder.layers.18': 'disk', 'decoder.layers.19': 'disk', 'decoder.layers.20': 'disk', 'decoder.layers.21': 'disk', 'decoder.layers.22': 'disk', 'decoder.layers.23': 'disk', 'decoder.layers.24': 'disk', 'decoder.layers.25': 'disk', 'decoder.layers.26': 'disk', 'decoder.layers.27': 'disk', 'decoder.layers.28': 'disk', 'decoder.layers.29': 'disk', 'decoder.layers.30': 'disk', 'decoder.layers.31': 'disk'}\n"
     ]
    }
   ],
   "source": [
    "max_mem = 2686198491 # 2G\n",
    "\n",
    "device_map = infer_auto_device_map(\n",
    "    model.model, \n",
    "    #max_memory={0: max_mem, 'cpu': max_mem*2},\n",
    "    max_memory={0: max_mem},\n",
    "    no_split_module_classes=[\"OPTDecoderLayer\"], \n",
    "    dtype='float16'\n",
    ")\n",
    "\n",
    "print(device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72887cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../offload_folder’: File exists\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/workspace/offload_filder'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mkdir ../offload_folder\n",
    "\n",
    "offload_folder = os.path.join(os.getcwd(), 'offload_filder')\n",
    "offload_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "811e37cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "model.decoder.embed_tokens.weight doesn't have any device set.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_checkpoint_and_dispatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#device_map=\"auto\",\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat16\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n\u001b[1;32m     12\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHugging Face is pushing the convention that a unicorn with two horns becomes a llama.\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/anaconda3/envs/ai/lib/python3.10/site-packages/accelerate/big_modeling.py:479\u001b[0m, in \u001b[0;36mload_checkpoint_and_dispatch\u001b[0;34m(model, checkpoint, device_map, max_memory, no_split_module_classes, offload_folder, offload_buffers, dtype, offload_state_dict, preload_module_classes)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offload_state_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    478\u001b[0m     offload_state_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m \u001b[43mload_checkpoint_in_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/data/anaconda3/envs/ai/lib/python3.10/site-packages/accelerate/utils/modeling.py:935\u001b[0m, in \u001b[0;36mload_checkpoint_in_model\u001b[0;34m(model, checkpoint, device_map, offload_folder, dtype, offload_state_dict, offload_buffers)\u001b[0m\n\u001b[1;32m    932\u001b[0m     module_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(module_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m device_map:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;66;03m# TODO: group all errors and raise at the end.\u001b[39;00m\n\u001b[0;32m--> 935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have any device set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    936\u001b[0m param_device \u001b[38;5;241m=\u001b[39m device_map[module_name]\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param_device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: model.decoder.embed_tokens.weight doesn't have any device set."
     ]
    }
   ],
   "source": [
    "load_checkpoint_and_dispatch(\n",
    "    model.model, \n",
    "    weights_path, \n",
    "    #device_map=\"auto\",\n",
    "    device_map=device_map, \n",
    "    offload_folder=offload_folder, \n",
    "    dtype='float16', \n",
    "    offload_state_dict=True\n",
    ")\n",
    "model.tie_weights()\n",
    "\n",
    "inputs = tokenizer(\"Hugging Face is pushing the convention that a unicorn with two horns becomes a llama.\", return_tensors=\"pt\")\n",
    "output = model.generate(inputs[\"input_ids\"].to(0), max_length=50, do_sample=True)\n",
    "\n",
    "print(tokenizer.decode(output[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb5b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
